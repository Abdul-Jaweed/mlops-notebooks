{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "\n",
    " - In data science work streams, *batch pipelines* involve touching varied data sources (databases, warehouses, data lakes), generating features, imputing, exploration and many other tasks all the way to generating trained model artifacts.\n",
    "\n",
    " - While doing so, we think of the process from the start to end as blocks that can be chained in a sequence (or more generally as a directed acyclic graph or DAG).\n",
    "\n",
    " - Some desirable properties we want from model pipelines are:\n",
    "  - ability to manage multiple pipelines\n",
    "  - ability to run blocks in a schedule (nightly, hourly)\n",
    "  - ability to detect if a previous block has not finished its part and quickly fix it! (*reliability is important*)\n",
    " \n",
    " - Ultimately we would like to manage pipelines without much manual work.\n",
    "\n",
    " - Workflow tools address these gaps. What they enable the user to do is \n",
    "  - allow easy specification of the DAG\n",
    "  - ensure the dependencies for each block are met\n",
    "  - schedule blocks to be run automatically\n",
    "\n",
    " - Further these tools also control resources (compute, storage etc) and perform monitoring to achieve these goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " - Example tools:\n",
    "  - [Airflow](https://airflow.apache.org/)\n",
    "  - [MLflow](https://mlflow.org/)\n",
    "  - [Luigi](https://github.com/spotify/luigi)\n",
    "  - [Metaflow](https://metaflow.org)\n",
    "  - [Kubeflow](https://www.kubeflow.org/)\n",
    "  - [Argo](https://github.com/argoproj/argo)\n",
    "\n",
    "\n",
    "#### TLDR\n",
    "\n",
    " - These tools are essential for production machine learning lifecyle management with multiple team members.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Goals\n",
    "\n",
    " - Build a batch pipeline running in a container\n",
    " - Use cron and Kubernetes for scheduling\n",
    " - Explore Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
