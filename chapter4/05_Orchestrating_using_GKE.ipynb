{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrating using Google Kubernetes Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Note: While exploring GKE, keep a tab on billing (check every so often)!** \n",
    "\n",
    "\n",
    "### Introduction to Google Kubernetes Engine by GCP\n",
    "\n",
    " - Google Kubernetes Engine (GKE) by GCP a managed service for running K8s, with key features such as security, scaling and multi-cluster support taken care of as part of K8s on their infrastructure.\n",
    "\n",
    " - GKE's operation is very similar to ECS.\n",
    "\n",
    " - Our **goal** will be to use GKE for deploying our recommendation system (the ML model we have been using).\n",
    " \t- We will first save our docker image to a Docker registry on GCP (this is called the Container Registry).\n",
    " \t- Next we will use that image while setting up a K8s cluster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Google Container Registry\n",
    "\n",
    " - We will use the docker login command with the previously created service account with the JSON based credentials we had saved.\n",
    "\n",
    "```bash\n",
    "(base) ttmac:~ theja$ cat model-user.json | docker login -u _json_key --password-stdin https://us.gcr.io\n",
    "Login Succeeded\n",
    "```\n",
    "\n",
    " - Tag the docker image with the Google container registry specific tag as follows:\n",
    "\n",
    "```bash\n",
    "(base) ttmac:~ theja$ docker tag prediction_service us.gcr.io/authentic-realm-276822/prediction_service\n",
    "(base) ttmac:~ theja$ docker images\n",
    "REPOSITORY                                                     TAG                 IMAGE ID            CREATED             SIZE\n",
    "prediction_service                                             latest              dd408a931e14        7 days ago          2.06GB\n",
    "us.gcr.io/authentic-realm-276822/prediction_service            latest              dd408a931e14        7 days ago          2.06GB\n",
    "weather_service                                                latest              20d340f941c0        9 days ago          496MB\n",
    "debian                                                         buster-slim         c7346dd7f20e        6 weeks ago         69.2MB\n",
    "continuumio/miniconda3                                         latest              b4adc22212f1        6 months ago        429MB\n",
    "hello-world                                                    latest              bf756fb1ae65        8 months ago        13.3kB\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " - Next, we push the local image to GCR. The upload status will keep getting updated.\n",
    "\n",
    "```bash\n",
    "(base) ttmac:~ theja$ docker push us.gcr.io/authentic-realm-276822/prediction_service\n",
    "The push refers to repository [us.gcr.io/authentic-realm-276822/prediction_service]\n",
    "d4bf100b2f89: Pushed\n",
    "6719394c8842: Pushed\n",
    "a432b6ec80f7: Pushing [>                                                  ]  20.81MB/1.635GB\n",
    "fcd8d39597dd: Pushing [========>                                          ]  24.11MB/149.1MB\n",
    "875120aa853c: Pushing [=====>                                             ]  23.17MB/210.4MB\n",
    "f2cb0ecef392: Layer already exists\n",
    "```\n",
    " - When its done, you will see the following:\n",
    "\n",
    "```bash\n",
    "(base) ttmac:~ theja$ docker push us.gcr.io/authentic-realm-276822/prediction_service\n",
    "The push refers to repository [us.gcr.io/authentic-realm-276822/prediction_service]\n",
    "d4bf100b2f89: Pushed\n",
    "6719394c8842: Pushed\n",
    "a432b6ec80f7: Pushed\n",
    "fcd8d39597dd: Pushed\n",
    "875120aa853c: Pushed\n",
    "f2cb0ecef392: Layer already exists\n",
    "latest: digest: sha256:f5b19d0e4510194ab8bdbed22f915fec8a07d1a465725ccfa6196782a480172c size: 1582\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " - We can verify that the prediction_service image is present in the GCR page.\n",
    "\n",
    "![gcr_image1](images/gcr_image1.png)\n",
    "\n",
    "![gcr_image2](images/gcr_image2.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Kubernetes Engine\n",
    "\n",
    " - We will now set up the K8s cluster. Lets start by accessing the GKE page.\n",
    "\n",
    "\n",
    "![gke01](images/gke01.png)\n",
    "\n",
    " - Click on `Deply container` next to the `Create cluster` button.\n",
    "\n",
    "![gke02](images/gke02.png)\n",
    "\n",
    " - Pick the existing cluster option and choose `select`.\n",
    "\n",
    "![gke03](images/gke03.png)\n",
    "\n",
    " - Choose the recently uploaded prediction_service image.\n",
    "\n",
    " ![gke04](images/gke04.png)\n",
    "\n",
    " - Hit continue.\n",
    "\n",
    " ![gke05](images/gke05.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " - On the next page, we will leave everything to default except for the name and then hit `Deploy` button.\n",
    "\n",
    " ![gke06](images/gke06.png)\n",
    " ![gke07](images/gke07.png)\n",
    "\n",
    " - It may take some time for the cluster to get fully set up.\n",
    "\n",
    " ![gke08](images/gke08.png)\n",
    "\n",
    "  - Recall the system level diagram.\n",
    "\n",
    " \t![kubernetes_cluster](images/kubernetes_cluster.svg)\n",
    "\t<div style=\"text-align: right\"> Source: https://www.gstatic.com/pantheon/images/container/kubernetes_cluster.svg </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  - Once the cluster is set up, we can investigate its properties.\n",
    "\n",
    "\n",
    " ![gke09](images/gke09.png)  \n",
    "\n",
    " ![gke10](images/gke10.png)  \n",
    "\n",
    " ![gke11](images/gke11.png)  \n",
    "\n",
    " ![gke12](images/gke12.png)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " - Just as we did in the local deployment, we will expose the cluster to be able to trigger prediction requests. We can do that by going to the Workload tab and clicking on the cluster.\n",
    "\n",
    " ![gke13](images/gke13.png)\n",
    "\n",
    " - We will next click on the `expose` button to the far right.\n",
    "\n",
    " ![gke14](images/gke14.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " - We will specify the container port as 80 (if you look at recommend.py we have specified port 80 where the flask app listens to requests).\n",
    "\n",
    " ![gke15](images/gke15.png)\n",
    "\n",
    " - Once the service is running, we can obtain the external IP.\n",
    "\n",
    "  ![gke16](images/gke16.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " - As expected, if we query without a payload we get a default response.\n",
    "\n",
    "  ![gke_browser1](images/gke_browser1.png)\n",
    "\n",
    "\n",
    " - With an example payload, we are able to retrieve the recommendations from real-time execution of the pytorch model.\n",
    "\n",
    "  ![gke_browser2](images/gke_browser2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " - To tear down the cluster, we first delete the service.\n",
    "\n",
    "\n",
    "![teardown_service1](images/teardown_service1.png)\n",
    "\n",
    "![teardown_service2](images/teardown_service2.png)\n",
    "\n",
    "![teardown_service3](images/teardown_service3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " - Finally, we can delete the workload itself.\n",
    "\n",
    "![teardown_workload1](images/teardown_workload1.png)\n",
    "![teardown_workload2](images/teardown_workload2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
