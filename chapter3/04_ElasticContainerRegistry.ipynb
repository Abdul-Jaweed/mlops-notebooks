{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestration using ECR and ECS - Part 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Intro\n",
    "\n",
    "> Orchestration means managing container life cycle from building them to deploying (which requires provisioning of appropriate compute resources, storage resources, networking resources), scaling, load-balancing and other tasks, while accounting for failures throughout.\n",
    "\n",
    "While there are many orchestration solutions, we will focus on a couple of them: ECS by AWS and Kubernetes (local hosted solution and managed by GCP). While there is Elastic Kubernetes Service (EKS) by AWS as well, we will omit it here, as the ideas are the same.\n",
    "\n",
    "Why should data science professions know such orchestration solutions?\n",
    "\n",
    " - Pro: Get key devops features (fault tolerance, scalability etc) with low on-going effort. The deployed service will not likely break down.\n",
    " - Con: There is a non-trivial setup cost/complexity.\n",
    "\n",
    "Next, we will (a) deploy our model serving docker image to the AWS container registry ECR, (b) use ECS to deploy a container based on that image, and (c) set up a load balancer that mediates requests to the prediction model.\n",
    "\n",
    "### Elastic Container Registry (ECR)\n",
    "\n",
    " - Sending the image to a model registry such as ECR is needed to access it at other places to create containers.\n",
    " - ECR allows for better integration with the AWS platform, and works with EKS as well.\n",
    " - We will create a docker image locally (can also be done on EC2) and *push it* to an ECR repository that we will create.\n",
    "\n",
    " - Navigate to the ECR link on the AWS console.\n",
    "\n",
    "![ecr_create0](images/ecr_create0.png) \n",
    "\n",
    " - Click create a repository 'Get Started' button. ECR can have multiple repositories and each repository can hold multiple images.\n",
    "\n",
    "![ecr_create1](images/ecr_create1.png) \n",
    "\n",
    " - Give a name to the repository. It will contain multiple Docker images.\n",
    "\n",
    "![ecr_create2](images/ecr_create2.png) \n",
    "\n",
    " - Review the current repository list.\n",
    "\n",
    "![ecr_create3](images/ecr_create3.png) \n",
    "\n",
    " - Next we will allow the programmatic user we created for accessing S3 (we gave the user name model-user) to also manage the ECR repositories. Navigate to IAM as shown below.\n",
    "\n",
    "![iam_ecr1](images/iam_ecr1.png) \n",
    "\n",
    " - Click on the user who we want to edit access controls for.\n",
    "\n",
    "![iam_ecr2](images/iam_ecr2.png) \n",
    "\n",
    " - Currently this user had S3 access (not relevant for us). \n",
    "\n",
    "![iam_ecr3](images/iam_ecr3.png) \n",
    "\n",
    " - Click on attaching existing policies and search for `AmazonEC2ContainerRegistryFullAccess`.\n",
    "\n",
    "![iam_ecr4](images/iam_ecr4.png) \n",
    "\n",
    " - Review your policy choice and proceed.\n",
    "\n",
    "![iam_ecr5](images/iam_ecr5.png) \n",
    "\n",
    " - You can see the summary of permissions that this programmatic user has.\n",
    "\n",
    "![iam_ecr6](images/iam_ecr6.png) \n",
    "\n",
    "\n",
    "### Creating the Model Prediction Docker Image\n",
    "\n",
    " - We will use the following flask app that uses the pytorch model to serve recommendations:\n",
    "\n",
    "```python\n",
    "from surprise import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import flask\n",
    "\n",
    "class MF(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_user, n_item, k=18, c_vector=1.0, c_bias=1.0):\n",
    "        super(MF, self).__init__()\n",
    "        self.k = k\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.c_bias = c_bias\n",
    "        self.c_vector = c_vector\n",
    "        \n",
    "        self.user = torch.nn.Embedding(n_user, k)\n",
    "        self.item = torch.nn.Embedding(n_item, k)\n",
    "        \n",
    "        # We've added new terms here:\n",
    "        self.bias_user = torch.nn.Embedding(n_user, 1)\n",
    "        self.bias_item = torch.nn.Embedding(n_item, 1)\n",
    "        self.bias = torch.nn.Parameter(torch.ones(1))\n",
    "    \n",
    "    def __call__(self, train_x):\n",
    "        user_id = train_x[:, 0]\n",
    "        item_id = train_x[:, 1]\n",
    "        vector_user = self.user(user_id)\n",
    "        vector_item = self.item(item_id)\n",
    "        \n",
    "        # Pull out biases\n",
    "        bias_user = self.bias_user(user_id).squeeze()\n",
    "        bias_item = self.bias_item(item_id).squeeze()\n",
    "        biases = (self.bias + bias_user + bias_item)\n",
    "        \n",
    "        ui_interaction = torch.sum(vector_user * vector_item, dim=1)\n",
    "        \n",
    "        # Add bias prediction to the interaction prediction\n",
    "        prediction = ui_interaction + biases\n",
    "        return prediction\n",
    "    \n",
    "    def loss(self, prediction, target):\n",
    "        loss_mse = F.mse_loss(prediction, target.squeeze())\n",
    "        \n",
    "        # Add new regularization to the biases\n",
    "        prior_bias_user =  l2_regularize(self.bias_user.weight) * self.c_bias\n",
    "        prior_bias_item = l2_regularize(self.bias_item.weight) * self.c_bias\n",
    "        \n",
    "        prior_user =  l2_regularize(self.user.weight) * self.c_vector\n",
    "        prior_item = l2_regularize(self.item.weight) * self.c_vector\n",
    "        total = loss_mse + prior_user + prior_item + prior_bias_user + prior_bias_item\n",
    "        return total\n",
    "\n",
    "def get_top_n(model,testset,trainset,uid_input,n=10):\n",
    "    \n",
    "    preds = []\n",
    "    try:\n",
    "        uid_input = int(trainset.to_inner_uid(uid_input))\n",
    "    except KeyError:\n",
    "        return preds        \n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    for uid, iid, _ in testset: #inefficient\n",
    "        try:\n",
    "            uid_internal = int(trainset.to_inner_uid(uid))\n",
    "        except KeyError:\n",
    "            continue\n",
    "        if uid_internal==uid_input:\n",
    "            try:\n",
    "                iid_internal = int(trainset.to_inner_iid(iid))\n",
    "                movie_name = df.loc[int(iid),'name']\n",
    "                preds.append((iid,movie_name,float(model(torch.tensor([[uid_input,iid_internal]])))))\n",
    "            except KeyError:\n",
    "                pass\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones\n",
    "    if preds is not None:\n",
    "        preds.sort(key=lambda x: x[1], reverse=True)\n",
    "        if len(preds) > n:\n",
    "            preds = preds[:n]\n",
    "    return preds\n",
    "\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "\n",
    "\n",
    "#Data\n",
    "df = pd.read_csv('./movies.dat',sep=\"::\",header=None,engine='python')\n",
    "df.columns = ['iid','name','genre']\n",
    "df.set_index('iid',inplace=True)\n",
    "data = Dataset.load_builtin('ml-100k',prompt=False) \n",
    "'''\n",
    "Exercise: remove the above dependency. \n",
    "Currently it downloads data from grouplens website and stores in .surprise folder in $HOME\n",
    "'''\n",
    "trainset = data.build_full_trainset()\n",
    "testset = trainset.build_anti_testset()\n",
    "\n",
    "#Parameters that are needed to reload the model from disk\n",
    "k = 10 #latent dimension\n",
    "c_bias = 1e-6\n",
    "c_vector = 1e-6\n",
    "model = MF(trainset.n_users, trainset.n_items, k=k, c_bias=c_bias, c_vector=c_vector)\n",
    "model.load_state_dict(torch.load('./pytorch_model'))\n",
    "model.eval() #no need for gradient computations in this setting\n",
    "\n",
    "\n",
    "# define a predict function as an endpoint\n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def predict():\n",
    "    data = {\"success\": False}\n",
    "\n",
    "    # check for passed in parameters   \n",
    "    params = flask.request.json\n",
    "    if params is None:\n",
    "        params = flask.request.args\n",
    "    \n",
    "    if \"uid\" in params.keys():\n",
    "        data[\"response\"] = get_top_n(model,testset,trainset,params['uid'],n=10) \n",
    "        data[\"success\"] = True\n",
    "        \n",
    "    # return a response in json format \n",
    "    return flask.jsonify(data)\n",
    "\n",
    "\n",
    "# start the flask app, allow remote connections\n",
    "app.run(host='0.0.0.0', port=80)\n",
    "```\n",
    " - The corresponding Dockerfile is below. The key additional files in addition to `recommend.py` above are:\n",
    "   - movies.dat\n",
    "   - pytorch_model\n",
    "\n",
    "```bash\n",
    "FROM continuumio/miniconda3:latest\n",
    "\n",
    "RUN conda install -y flask pandas \\\n",
    " && conda install -c conda-forge scikit-surprise \\\n",
    " && conda install pytorch torchvision cpuonly -c pytorch \n",
    "\n",
    "COPY recommend.py recommend.py\n",
    "COPY movies.dat movies.dat\n",
    "COPY pytorch_model pytorch_model\n",
    "\n",
    "ENTRYPOINT [\"python\",\"recommend.py\"]\n",
    "```\n",
    "\n",
    " - The miniconda image above is from [https://hub.docker.com/r/continuumio/miniconda3](https://hub.docker.com/r/continuumio/miniconda3).\n",
    "\n",
    " - Building an image based on the above file and running our prediction locally can be done using the following commands:\n",
    "\n",
    "```bash\n",
    "docker image build -t \"prediction_service\" .\n",
    "docker run -d -p 5000:5000 prediction_service\n",
    "docker ps -a #check what all containers were/are running\n",
    "docker kill container_id #after checking that the service runs, we can safely stop and delete the container.\n",
    "docker rm container_id\n",
    "``` \n",
    "\n",
    " - If we run a container based on this image, the python file and others will be in the root (`/`) folder and will be run by the root user. While we will not improve this here, it is better to run services as non-root users.\n",
    "\n",
    "\n",
    "### Sending our Docker Image to ECR\n",
    "\n",
    " - We will follow the instruction [here](https://docs.aws.amazon.com/AmazonECR/latest/userguide/getting-started-cli.html) to push our image to the repository we just created.\n",
    "\n",
    "\n",
    " - Assuming you have the aws CLI configured with the secret keys, run the following command:\n",
    "\n",
    " ```bash\n",
    "aws ecr get-login-password --region region | docker login --username AWS --password-stdin aws_account_id.dkr.ecr.region.amazonaws.com\n",
    " ```\n",
    "\n",
    " - Substitute `region` with `us-east-1` etc (check the URL on the ECR page) as well as `aws_account_id` with the actual account id. We should get a prompt saying 'Login Succeeded'.\n",
    "\n",
    " - Lets tag our image before sending it to ECR (replace account id and region below as well):\n",
    "\n",
    "```bash\n",
    "(datasci-dev) ttmac:docker-prediction-service theja$ docker tag prediction_service aws_account_id.dkr.ecr.region.amazonaws.com/models:recommendations\n",
    "(datasci-dev) ttmac:docker-prediction-service theja$ docker images\n",
    "REPOSITORY                                            TAG                 IMAGE ID            CREATED             SIZE\n",
    "aws_account_id.dkr.ecr.region.amazonaws.com/recommendations   pytorch_model       364179b27eb1        21 minutes ago      2.06GB\n",
    "weather_service                                                latest              20d340f941c0        2 days ago          496MB\n",
    "debian                                                         buster-slim         c7346dd7f20e        5 weeks ago         69.2MB\n",
    "continuumio/miniconda3                                         latest              b4adc22212f1        6 months ago        429MB\n",
    "hello-world                                                    latest              bf756fb1ae65        8 months ago        13.3kB\n",
    "```\n",
    "\n",
    " - Pushing to ECR is achieved by the following:\n",
    "\n",
    "```bash\n",
    "docker push aws_account_id.dkr.region.amazonaws.com/recommendations:pytorch_model\n",
    "```\n",
    "\n",
    " - You should see the update progress (this is a large upload!)\n",
    "\n",
    "```bash\n",
    "The push refers to repository [aws_account_id.dkr.ecr.us-east-2.amazonaws.com/recommendations]\n",
    "a5649bbe3e5f: Pushed\n",
    "5c87fc4d582f: Pushed\n",
    "e1e8d92205bf: Pushed\n",
    "5c6c81390816: Pushing [=========================>                         ]  848.8MB/1.635GB\n",
    "fcd8d39597dd: Pushed\n",
    "875120aa853c: Pushed\n",
    "f2cb0ecef392: Pushed\n",
    "```\n",
    "\n",
    " - And the push conclusion:\n",
    "\n",
    "```bash\n",
    "(datasci-dev) ttmac:docker-prediction-service theja$ docker push aws_account_id.dkr.ecr.us-east-2.amazonaws.com/recommendations:pytorch_model\n",
    "The push refers to repository [aws_account_id.dkr.ecr.us-east-2.amazonaws.com/recommendations]\n",
    "a5649bbe3e5f: Pushed\n",
    "5c87fc4d582f: Pushed\n",
    "e1e8d92205bf: Pushed\n",
    "5c6c81390816: Pushed\n",
    "fcd8d39597dd: Pushed\n",
    "875120aa853c: Pushed\n",
    "f2cb0ecef392: Pushed\n",
    "pytorch_model: digest: sha256:af5dfaf227cd96c4ca8ca952c511fb4274c59d76574726462137bc7c4230be07 size: 1793\n",
    "```\n",
    "\n",
    "\n",
    " - On the ECR page, if we look at the images in the recommendations repository, it will contain our recently uploaded image.\n",
    "\n",
    "![ecr_image1](images/ecr_image1.png)\n",
    "\n",
    " - There is a friendly help box that details specific (to your account) commands for pushing images to ECR on the above page as well. You could use that as a guiding reference, or the [help](https://docs.aws.amazon.com/AmazonECR/latest/userguide/getting-started-cli.html) page.\n",
    "\n",
    "![ecr_push](images/ecr_push.png)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
