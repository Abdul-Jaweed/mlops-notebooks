{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Go through the examples in [https://sparkbyexamples.com/](https://sparkbyexamples.com/) with notebooks using your Databricks community edition account.\n",
    "\n",
    "2. Go through this article to learn more about the [spark architecture](https://luminousmen.com/post/spark-anatomy-of-spark-application).\n",
    "\n",
    "3. Learn the difference between a data lake and a data warehouse [here](https://luminousmen.com/post/data-lake-vs-data-warehouse).\n",
    "\n",
    "4. Try to write the non-sql version of the code shown to obtain the top 10 movies by average rating.\n",
    "\n",
    "\n",
    "5. (*hard*) Try to use the idea of Pandas UDFs to generate a new dataframe of users and a derived attribute that captures whether their average rating over time has increased or decreased. While this can be done on a single machine in various ways, pandas UDFs let us do a groupby on users and do the same computation in a distributed way. In each group, we could fit a linear model using the scikit-learn library and get the trend.\n",
    "\n",
    "6. Run the models available at [http://surpriselib.com/](http://surpriselib.com/) in a spark environment and see if you can take advantage of distributed computation with any of them.\n",
    "\n",
    "7. Use user defined functions instead of the inbuilt aggregate functions (such as mean, sum) to create new columns in a pyspark dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
