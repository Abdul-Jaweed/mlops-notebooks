{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCP Serverless Model Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify the flask app that we had before, by again specifying the requirements.txt and the main python file appropriately. \n",
    "We will also increase the memory to 2GB and the timeout to 180 seconds. You will see that the following deployment has a lot of inefficiencies (can you spot the redundacy in loading the model and the predictions below?).\n",
    "\n",
    "The requirements file will have the following entries:\n",
    "\n",
    "```bash\n",
    "numpy\n",
    "flask\n",
    "pandas\n",
    "google-cloud-storage\n",
    "scikit-surprise\n",
    "pickle5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The main file is also modified accordingly. Note that if we reload the model and the metadata on every request, it will be extremely inefficient. To fix that we can use global variables. This is not a good choice in much of python programming, but quite useful here. Essentially, global variables allow us to cache some of the objects, for faster response times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_n = None\n",
    "\n",
    "def recommend(request):\n",
    "\n",
    "    global top_n\n",
    "\n",
    "    from surprise import Dataset\n",
    "    import pandas as pd\n",
    "    import flask\n",
    "    from google.cloud import storage\n",
    "    import pickle5\n",
    "\n",
    "    def load(file_name):\n",
    "        dump_obj = pickle5.load(open(file_name, 'rb'))\n",
    "        return dump_obj['predictions'], dump_obj['algo']\n",
    "\n",
    "    def get_top_n(predictions, n=10):\n",
    "\n",
    "        def defaultdict(default_type):\n",
    "            class DefaultDict(dict):\n",
    "                def __getitem__(self, key):\n",
    "                    if key not in self:\n",
    "                        dict.__setitem__(self, key, default_type())\n",
    "                    return dict.__getitem__(self, key)\n",
    "            return DefaultDict()\n",
    "\n",
    "        # First map the predictions to each user.\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, true_r, est, _ in predictions:\n",
    "            top_n[uid].append((iid, est))\n",
    "\n",
    "        # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[uid] = user_ratings[:n]\n",
    "\n",
    "        return top_n\n",
    "\n",
    "\n",
    "    data = {\"success\": False}\n",
    "    params = request.get_json()\n",
    "    if \"uid\" in params:\n",
    "\n",
    "        if not top_n:\n",
    "            bucket_name = \"theja_model_store\"\n",
    "            storage_client = storage.Client()\n",
    "            bucket = storage_client.get_bucket(bucket_name)\n",
    "            blob = bucket.blob(\"serverless/surprise_model/v1a\")\n",
    "            blob.download_to_filename(\"/tmp/surprise_model\")    #ideally we should be reading things into memory\n",
    "            blob = bucket.blob(\"serverless/surprise_model/v1b\")\n",
    "            blob.download_to_filename(\"/tmp/movies.dat\")\n",
    "            df = pd.read_csv('/tmp/movies.dat',sep=\"::\",header=None,engine='python')\n",
    "            df.columns = ['iid','name','genre']\n",
    "            df.set_index('iid',inplace=True)\n",
    "            predictions, algo = load('/tmp/surprise_model')\n",
    "            top_n = get_top_n(predictions, n=5)\n",
    "\n",
    "        data[\"response\"] = str([df.loc[int(iid),'name'] for (iid, _) in top_n[params.get(\"uid\")]])\n",
    "        data[\"success\"] = True\n",
    "        \n",
    "    # return a response in json format \n",
    "    return flask.jsonify(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can test the function on the GCP console with a request JSON `{\"uid\":\"206\"}`.\n",
    "\n",
    "![cf_model_successful](images/cf_model_successful.png)\n",
    "\n",
    "\n",
    "_As an exercise, think of ways to make the whole setup above lightweight in terms of model and data size._\n",
    "\n",
    "_Deploying the pytorch model after removing the dependecy on surprise is also a good challenge to tackle._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Management\n",
    "\n",
    " - It is a bad idea to allow unauthenticated access\n",
    " - There are ways of restricting who can reach this model serving endpoint.\n",
    "   - One way is to disable unauthenticated access while creating the function.\n",
    "   - Once we do that, we can create a permission structure based on GCP best practices.\n",
    " - We will omit the details here.\n",
    "\n",
    "\n",
    "### Updating Models and Monitoring\n",
    "\n",
    " - We can easily update our endpoint by rewriting the files we uploaded to GCS.\n",
    " - A cleaner way is to create another cloud function.\n",
    " - The function itself can have logic to reload files using the `google-cloud-storage` module based on time elapsed (say using `datetime`).\n",
    " - Monitoring is very important, not just to know if our model performance has changed over time, but also to measure things such as latency, bugs and API access patterns. We will revisit this topic in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
